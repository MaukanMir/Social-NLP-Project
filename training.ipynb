{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Models \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Data Processing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "\n",
    "np.random.seed(1)\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "import torch\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold, cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "def read_dataframes(PATH, filepaths):\n",
    "\n",
    "  dataframes = []\n",
    "\n",
    "  for file in filepaths:\n",
    "    dataframes.append(pd.read_csv(PATH + file +'.csv'))\n",
    "  \n",
    "  return dataframes\n",
    "\n",
    "def check_class_imbalance(df):\n",
    "  y = df.values[:,-1]\n",
    "  counter = Counter(y)\n",
    "  for k,v in counter.items():\n",
    "    per = v/len(y) * 100\n",
    "    print(\"Class=%s, Count=%d, Percentage=%.3f%%\" % (k,v, per))\n",
    "\n",
    "def sentiment_score(review, tokenizer, model):\n",
    "  tokens = tokenizer.encode(review, return_tensors='pt')\n",
    "  result = model(tokens)\n",
    "  return int(torch.argmax(result.logits)) +1\n",
    "\n",
    "def get_selected_models(names):\n",
    "  \"\"\"\n",
    "  Returns selected models for ML processing\n",
    "\n",
    "  Args:\n",
    "      names (_type_):List\n",
    "\n",
    "  Returns:\n",
    "      List of models\n",
    "  \"\"\"\n",
    "  models = {\n",
    "    \"LDA\": LinearDiscriminantAnalysis(),\n",
    "    \"GPC\": GaussianProcessClassifier(),\n",
    "    \"GNB\": GaussianNB(),\n",
    "    \"SVC\": SVC(),\n",
    "    \"LR\":LogisticRegression(max_iter=1000),\n",
    "    \"KNN\": KNeighborsClassifier(),\n",
    "    \"DTC\": DecisionTreeClassifier(),\n",
    "    \"GBC\":GradientBoostingClassifier(),\n",
    "    \"RFC\":RandomForestClassifier(),\n",
    "    \"XGB\": XGBClassifier()\n",
    "  }\n",
    "  \n",
    "  return [models[model] for model in names]\n",
    "def evaluate_model(X, y, model):\n",
    "  # define evaluation procedure\n",
    "  cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "  \n",
    "  metric = make_scorer(accuracy_score)\n",
    "  # evaluate model\n",
    "  scores = cross_val_score(model, X, y, scoring=metric, cv=cv, n_jobs=-1)\n",
    "  return scores\n",
    "def testing_selected_models(names:list, models:list, X:pd.DataFrame, y:pd.Series):\n",
    "    \"\"\"\n",
    "    Runs multiple subsets on folds of data\n",
    "\n",
    "    Args:\n",
    "        names (list): _description_\n",
    "        models (list): _description_\n",
    "    \"\"\"\n",
    "    model_performance = []\n",
    "    for i in range(len(models)):\n",
    "        model = models[i]\n",
    "        # Evaluate the model\n",
    "        scores = evaluate_model(X, y, model)\n",
    "        # summarize and store\n",
    "        model_performance.append({\n",
    "            \"Model\": names[i],\n",
    "            \"Mean\": np.mean(scores),\n",
    "            \"STD\":np.std(scores)\n",
    "        })\n",
    "    performance_df = pd.DataFrame(model_performance)\n",
    "    return performance_df.sort_values(by=\"Mean\", ascending=False)\n",
    "\n",
    "def svm_tune_grid_search(X,y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "    \n",
    "    model = SVC()\n",
    "    \n",
    "    param_grid = {\n",
    "        'model__kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "        'model__C': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1]\n",
    "    }\n",
    "    \n",
    "    grid_search = GridSearchCV(model, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    print(\"Best parameters:\", grid_search.best_params_)\n",
    "    print(\"Best cross-validation score: {:.3f}\".format(grid_search.best_score_))\n",
    "    \n",
    "    y_pred = grid_search.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f'Test accuracy: {accuracy:.3f}')\n",
    "    \n",
    "    return grid_search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"/Users/maukanmir/Downloads/archive/\"\n",
    "\n",
    "filepaths = ['Education', 'Sports', 'Finance', 'Politics']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "edu_df, sport_df, finance_df, politics_df = read_dataframes(PATH, filepaths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of NA values: Text     0\n",
      "Label    0\n",
      "dtype: int64\n",
      "Number of Duplicated values: 0\n",
      "(52, 2)\n",
      "Number of NA values: Text     0\n",
      "Label    0\n",
      "dtype: int64\n",
      "Number of Duplicated values: 0\n",
      "(56, 2)\n",
      "Number of NA values: Text     0\n",
      "Label    0\n",
      "dtype: int64\n",
      "Number of Duplicated values: 0\n",
      "(48, 2)\n",
      "Number of NA values: Text     0\n",
      "Label    0\n",
      "dtype: int64\n",
      "Number of Duplicated values: 0\n",
      "(53, 2)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data_frames = [edu_df, sport_df, finance_df, politics_df ]\n",
    "\n",
    "for df in data_frames:\n",
    "  print(f\"Number of NA values: {df.isna().sum()}\")\n",
    "  print(f\"Number of Duplicated values: {df.duplicated().sum()}\")\n",
    "  print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check for class imbalances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------\n",
      "Topic is Education\n",
      "Class=positive, Count=26, Percentage=50.000%\n",
      "Class=negative, Count=26, Percentage=50.000%\n",
      "------------------------\n",
      "Topic is Sports\n",
      "Class=positive, Count=28, Percentage=50.000%\n",
      "Class=negative, Count=28, Percentage=50.000%\n",
      "------------------------\n",
      "Topic is Finance\n",
      "Class=positive, Count=34, Percentage=70.833%\n",
      "Class=negative, Count=14, Percentage=29.167%\n",
      "------------------------\n",
      "Topic is Politics\n",
      "Class=positive, Count=25, Percentage=47.170%\n",
      "Class=negative, Count=28, Percentage=52.830%\n"
     ]
    }
   ],
   "source": [
    "for topic, df in zip(filepaths, data_frames):\n",
    "  print(\"------------------------\")\n",
    "  print(f\"Topic is {topic}\")\n",
    "  check_class_imbalance(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = f'cardiffnlp/twitter-roberta-base-sentiment'\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in data_frames:\n",
    "  df[\"Label\"] = df[\"Label\"].apply(lambda x: 1 if x == 'negative' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for df in data_frames:\n",
    "  df[\"BERT_score\"] = df[\"Text\"].apply(lambda review: sentiment_score(review, tokenizer, model))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(max_features=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, df in enumerate(data_frames):\n",
    "  df[\"Topic\"] = idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.concat([edu_df, sport_df, finance_df, politics_df], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(209, 4)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Separate Feature variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = final_df.drop(\"Label\", axis=1), final_df['Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_matrix = tfidf.fit_transform(X['Text'])\n",
    "\n",
    "# Convert to DataFrame\n",
    "tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=tfidf.get_feature_names_out())\n",
    "\n",
    "# Concatenate with original data\n",
    "X = pd.concat([X.drop(\"Text\", axis=1), tfidf_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['LR', 'SVC', 'GBC', 'XGB','GNB', 'KNN', 'DTC', 'RFC', 'GPC', 'LDA']\n",
    "\n",
    "models = get_selected_models(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Mean</th>\n",
       "      <th>STD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LR</td>\n",
       "      <td>0.875714</td>\n",
       "      <td>0.077509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.875714</td>\n",
       "      <td>0.077509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GPC</td>\n",
       "      <td>0.874127</td>\n",
       "      <td>0.077386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>RFC</td>\n",
       "      <td>0.866111</td>\n",
       "      <td>0.078537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GBC</td>\n",
       "      <td>0.859762</td>\n",
       "      <td>0.074066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.854762</td>\n",
       "      <td>0.082396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XGB</td>\n",
       "      <td>0.843810</td>\n",
       "      <td>0.073936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DTC</td>\n",
       "      <td>0.816349</td>\n",
       "      <td>0.107081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GNB</td>\n",
       "      <td>0.767063</td>\n",
       "      <td>0.074106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LDA</td>\n",
       "      <td>0.703413</td>\n",
       "      <td>0.100109</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Model      Mean       STD\n",
       "0    LR  0.875714  0.077509\n",
       "1   SVC  0.875714  0.077509\n",
       "8   GPC  0.874127  0.077386\n",
       "7   RFC  0.866111  0.078537\n",
       "2   GBC  0.859762  0.074066\n",
       "5   KNN  0.854762  0.082396\n",
       "3   XGB  0.843810  0.073936\n",
       "6   DTC  0.816349  0.107081\n",
       "4   GNB  0.767063  0.074106\n",
       "9   LDA  0.703413  0.100109"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_selected_models(names, models, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
