{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(1)\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "import torch\n",
    "\n",
    "\n",
    "def read_dataframes(PATH, filepaths):\n",
    "\n",
    "  dataframes = []\n",
    "\n",
    "  for file in filepaths:\n",
    "    dataframes.append(pd.read_csv(PATH + file +'.csv'))\n",
    "  \n",
    "  return dataframes\n",
    "\n",
    "def check_class_imbalance(df):\n",
    "  y = df.values[:,-1]\n",
    "  counter = Counter(y)\n",
    "  for k,v in counter.items():\n",
    "    per = v/len(y) * 100\n",
    "    print(\"Class=%s, Count=%d, Percentage=%.3f%%\" % (k,v, per))\n",
    "\n",
    "def sentiment_score(review, tokenizer, model):\n",
    "  tokens = tokenizer.encode(review, return_tensors='pt')\n",
    "  result = model(tokens)\n",
    "  return int(torch.argmax(result.logits)) +1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"/Users/maukanmir/Downloads/archive/\"\n",
    "\n",
    "filepaths = ['Education', 'Sports', 'Finance', 'Politics']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "edu_df, sport_df, finance_df, politics_df = read_dataframes(PATH, filepaths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of NA values: Text     0\n",
      "Label    0\n",
      "dtype: int64\n",
      "Number of Duplicated values: 0\n",
      "(52, 2)\n",
      "Number of NA values: Text     0\n",
      "Label    0\n",
      "dtype: int64\n",
      "Number of Duplicated values: 0\n",
      "(56, 2)\n",
      "Number of NA values: Text     0\n",
      "Label    0\n",
      "dtype: int64\n",
      "Number of Duplicated values: 0\n",
      "(48, 2)\n",
      "Number of NA values: Text     0\n",
      "Label    0\n",
      "dtype: int64\n",
      "Number of Duplicated values: 0\n",
      "(53, 2)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data_frames = [edu_df, sport_df, finance_df, politics_df ]\n",
    "\n",
    "for df in data_frames:\n",
    "  print(f\"Number of NA values: {df.isna().sum()}\")\n",
    "  print(f\"Number of Duplicated values: {df.duplicated().sum()}\")\n",
    "  print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check for class imbalances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------\n",
      "Topic is Education\n",
      "Class=positive, Count=26, Percentage=50.000%\n",
      "Class=negative, Count=26, Percentage=50.000%\n",
      "------------------------\n",
      "Topic is Sports\n",
      "Class=positive, Count=28, Percentage=50.000%\n",
      "Class=negative, Count=28, Percentage=50.000%\n",
      "------------------------\n",
      "Topic is Finance\n",
      "Class=positive, Count=34, Percentage=70.833%\n",
      "Class=negative, Count=14, Percentage=29.167%\n",
      "------------------------\n",
      "Topic is Politics\n",
      "Class=positive, Count=25, Percentage=47.170%\n",
      "Class=negative, Count=28, Percentage=52.830%\n"
     ]
    }
   ],
   "source": [
    "for topic, df in zip(filepaths, data_frames):\n",
    "  print(\"------------------------\")\n",
    "  print(f\"Topic is {topic}\")\n",
    "  check_class_imbalance(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9fb7789fe364c37a8c28846dd22d9ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d00ed038573e47d0ba133076b8f24979",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35629abda4c1499fbdc5c265afaaae8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a7fc8e28e834430bd7e9f8df940d764",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2901f829ffa746a9a3c310d87c1813a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"google-bert/bert-base-uncased\")\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"google-bert/bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in data_frames:\n",
    "  df[\"Label\"] = df[\"Label\"].apply(lambda x: 1 if x == 'negative' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for df in data_frames:\n",
    "  df[\"BERT_score\"] = df[\"Text\"].apply(lambda review: sentiment_score(review, tokenizer, model))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
